#Basic Binary Suicidal Ideation Classifier
#Takes a set of reddit posts and determines whether a post is suicidal or non-suicidal
#Brayden Cloutier
#Created 2/13/2025

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from transformers import AlbertTokenizer, AlbertModel
import sentencepiece
import torch
from torch.utils.data import DataLoader, TensorDataset


#Convert classes to binary: suicide to 1, non-suicide to 0
def to_binary(label_item):
    if label_item == "suicide":
        return 1
    elif label_item == "non-suicide":
        return 0
    else:
        print("Non-standard label detected!")

def preprocess(dataset, tokenizer, model):
    batch_size = 96
    embedded_tokens = []

    #Initialize DataLoader
    tokenized = tokenizer.batch_encode_plus(dataset.tolist(), return_tensors='pt', padding=True, truncation=True)

    # Create TensorDataset for DataLoader(generated by ChatGPT
    dataset_tensors = TensorDataset(tokenized['input_ids'], tokenized['attention_mask'])

    data_loader = DataLoader(dataset_tensors, batch_size=batch_size, shuffle=False)

    with torch.no_grad():
        torch.set_num_threads(torch.get_num_threads())
        for counter, batch in enumerate(data_loader):
            #next 2 lines generated by chatGPT
            input_ids, attention_mask = batch[0], batch[1]
            outputs = model(input_ids=input_ids, attention_mask=attention_mask)
            cls_embeddings = outputs.last_hidden_state[:, 0, :]

            flattened_embeddings = cls_embeddings.detach().cpu().numpy()
            embedded_tokens.extend(flattened_embeddings)
            print(f"Embedded batch #{counter + 1}")
    return np.array(embedded_tokens)

#Load in Dataset, use smaller sample size of 20k for testing
input_dataset = pd.read_csv('First/Suicide_Detection.csv', nrows=20000)

#Split into train, dev and test.  8/1/1 split
train_dataset, dev_test_dataset = train_test_split(input_dataset, test_size=0.2, random_state=42)
dev_dataset, test_dataset = train_test_split(dev_test_dataset, test_size=0.5, random_state=42)

#Vertical split into features and labels
train_feature = train_dataset["text"].to_numpy()
train_label = train_dataset["class"].apply(to_binary).to_numpy()

dev_feature = dev_dataset["text"].to_numpy()
dev_label = dev_dataset["class"].apply(to_binary).to_numpy()

test_feature = test_dataset["text"].to_numpy()
test_label = test_dataset["class"].apply(to_binary).to_numpy()
# print(len(train_feature))
#^output: 185659 for full dataset

# Load ALBERT tokenizer and model
model_name = "albert-base-v2"
albert_tokenizer = AlbertTokenizer.from_pretrained(model_name)
albert_model = AlbertModel.from_pretrained(model_name)
print("Beginning training set embedding")
processed_train_feature = pd.DataFrame(preprocess(train_feature, albert_tokenizer, albert_model))
print("Beginning development set embedding")
processed_dev_feature = pd.DataFrame(preprocess(dev_feature, albert_tokenizer, albert_model))
print("Beginning test set embedding")
processed_test_feature = pd.DataFrame(preprocess(test_feature, albert_tokenizer, albert_model))

#Save to csv
print("Saving train to csv")
processed_train_feature.to_csv("X_train.csv", index=False)
train_label.to_csv("y_train.csv", index=False)
print("Saving dev to csv")
processed_dev_feature.to_csv("X_dev.csv", index=False)
dev_label.to_csv("y_dev.csv", index=False)
print("Saving test to csv")
processed_test_feature.to_csv("X_test.csv", index=False)
test_label.to_csv("y_test.csv", index=False)



